{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_import import import_user_ratings, import_semantic, generate_random_user_ratings_input\n",
    "from bliga import BookRecommendationSystem\n",
    "from tuner import HyperparameterTuner\n",
    "from evaluation import Evaluator\n",
    "\n",
    "\n",
    "# File paths for data import\n",
    "user_ratings_file = \"user_ratings.csv\"\n",
    "semantic_file = \"semantic.csv\"\n",
    "\n",
    "# Import data\n",
    "user_ratings = import_user_ratings(user_ratings_file)\n",
    "semantic = import_semantic(semantic_file)\n",
    "\n",
    "# Generate user_ratings_input\n",
    "user_ratings_input = generate_random_user_ratings_input(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'pop_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Surface\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\Surface\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Surface\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'pop_size'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtuner_plot\u001b[39;00m\n\u001b[0;32m      2\u001b[0m filename \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcheckpoint_160.xlsx\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m pop_size_list, mutation_rate_list, num_generations_list, crossover_func_list, mutation_func_list, no_rec_list, best_solution_list, semratings_dict_list, fitness_scores_dict_list, best_solutions_by_generation_list \u001b[39m=\u001b[39m tuner_plot\u001b[39m.\u001b[39;49mread_excel(filename)\n",
      "File \u001b[1;32md:\\PROJECTS\\Github\\book-recommender-using-cf-and-ga\\Final Algorithm\\Book Recommender - Copy\\tuner_plot.py:8\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_excel\u001b[39m(filename):\n\u001b[0;32m      7\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_excel(filename)\n\u001b[1;32m----> 8\u001b[0m     pop_size_list \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39;49m\u001b[39mpop_size\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mtolist()\n\u001b[0;32m      9\u001b[0m     mutation_rate_list \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mmutation_rate\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mtolist()\n\u001b[0;32m     10\u001b[0m     num_generations_list \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mnum_generations\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mtolist()\n",
      "File \u001b[1;32mc:\\Users\\Surface\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3762\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\Surface\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'pop_size'"
     ]
    }
   ],
   "source": [
    "import tuner_plot\n",
    "filename = 'checkpoint_160.xlsx'\n",
    "pop_size_list, mutation_rate_list, num_generations_list, crossover_func_list, mutation_func_list, no_rec_list, best_solution_list, semratings_dict_list, fitness_scores_dict_list, best_solutions_by_generation_list = tuner_plot.read_excel(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations_list = [\n",
    "    (50, 0.1, 10, \"one_point\", \"swap\", 5),\n",
    "    (50, 0.1, 10, \"one_point\", \"swap\", 10),\n",
    "    (50, 0.1, 10, \"one_point\", \"swap\", 15),\n",
    "    (50, 0.1, 10, \"one_point\", \"inversion\", 5),\n",
    "    (50, 0.1, 10, \"one_point\", \"inversion\", 10),\n",
    "    (50, 0.1, 10, \"one_point\", \"inversion\", 15),\n",
    "    (50, 0.1, 10, \"uniform\", \"swap\", 5),\n",
    "    (50, 0.1, 10, \"uniform\", \"swap\", 10),\n",
    "    (50, 0.1, 10, \"uniform\", \"swap\", 15),\n",
    "    (50, 0.1, 10, \"uniform\", \"inversion\", 5),\n",
    "    (50, 0.1, 10, \"uniform\", \"inversion\", 10),\n",
    "    (50, 0.1, 10, \"uniform\", \"inversion\", 15),\n",
    "    (50, 0.1, 20, \"one_point\", \"swap\", 5),\n",
    "    (50, 0.1, 20, \"one_point\", \"swap\", 10),\n",
    "    (50, 0.1, 20, \"one_point\", \"swap\", 15),\n",
    "    (50, 0.1, 20, \"one_point\", \"inversion\", 5),\n",
    "    (50, 0.1, 20, \"one_point\", \"inversion\", 10),\n",
    "    (50, 0.1, 20, \"one_point\", \"inversion\", 15),\n",
    "    (50, 0.1, 20, \"uniform\", \"swap\", 5),\n",
    "    (50, 0.1, 20, \"uniform\", \"swap\", 10),\n",
    "    (50, 0.1, 20, \"uniform\", \"swap\", 15),\n",
    "    (50, 0.1, 20, \"uniform\", \"inversion\", 5),\n",
    "    (50, 0.1, 20, \"uniform\", \"inversion\", 10),\n",
    "    (50, 0.1, 20, \"uniform\", \"inversion\", 15),\n",
    "    (50, 0.1, 40, \"one_point\", \"swap\", 5),\n",
    "    (50, 0.1, 40, \"one_point\", \"swap\", 10),\n",
    "    (50, 0.1, 40, \"one_point\", \"swap\", 15),\n",
    "    (50, 0.1, 40, \"one_point\", \"inversion\", 5),\n",
    "    (50, 0.1, 40, \"one_point\", \"inversion\", 10),\n",
    "    (50, 0.1, 40, \"one_point\", \"inversion\", 15),\n",
    "    (50, 0.1, 40, \"uniform\", \"swap\", 5),\n",
    "    (50, 0.1, 40, \"uniform\", \"swap\", 10),\n",
    "    (50, 0.1, 40, \"uniform\", \"swap\", 15),\n",
    "    (50, 0.1, 40, \"uniform\", \"inversion\", 5),\n",
    "    (50, 0.1, 40, \"uniform\", \"inversion\", 10),\n",
    "    (50, 0.1, 40, \"uniform\", \"inversion\", 15),\n",
    "    (50, 0.5, 10, \"one_point\", \"swap\", 5),\n",
    "    (50, 0.5, 10, \"one_point\", \"swap\", 10),\n",
    "    (50, 0.5, 10, \"one_point\", \"swap\", 15),\n",
    "    (50, 0.5, 10, \"one_point\", \"inversion\", 5),\n",
    "    (50, 0.5, 10, \"one_point\", \"inversion\", 10),\n",
    "    (50, 0.5, 10, \"one_point\", \"inversion\", 15),\n",
    "    (50, 0.5, 10, \"uniform\", \"swap\", 5),\n",
    "    (50, 0.5, 10, \"uniform\", \"swap\", 10),\n",
    "    (50, 0.5, 10, \"uniform\", \"swap\", 15),\n",
    "    (50, 0.5, 10, \"uniform\", \"inversion\", 5),\n",
    "    (50, 0.5, 10, \"uniform\", \"inversion\", 10),\n",
    "    (50, 0.5, 10, \"uniform\", \"inversion\", 15),\n",
    "    (50, 0.5, 20, \"one_point\", \"swap\", 5),\n",
    "    (50, 0.5, 20, \"one_point\", \"swap\", 10),\n",
    "    (50, 0.5, 20, \"one_point\", \"swap\", 15),\n",
    "    (50, 0.5, 20, \"one_point\", \"inversion\", 5),\n",
    "    (50, 0.5, 20, \"one_point\", \"inversion\", 10),\n",
    "    (50, 0.5, 20, \"one_point\", \"inversion\", 15),\n",
    "    (50, 0.5, 20, \"uniform\", \"swap\", 5),\n",
    "    (50, 0.5, 20, \"uniform\", \"swap\", 10),\n",
    "    (50, 0.5, 20, \"uniform\", \"swap\", 15),\n",
    "    (50, 0.5, 20, \"uniform\", \"inversion\", 5),\n",
    "    (50, 0.5, 20, \"uniform\", \"inversion\", 10),\n",
    "    (50, 0.5, 20, \"uniform\", \"inversion\", 15),\n",
    "    (50, 0.5, 40, \"one_point\", \"swap\", 5),\n",
    "    (50, 0.5, 40, \"one_point\", \"swap\", 10),\n",
    "    (50, 0.5, 40, \"one_point\", \"swap\", 15),\n",
    "    (50, 0.5, 40, \"one_point\", \"inversion\", 5),\n",
    "    (50, 0.5, 40, \"one_point\", \"inversion\", 10),\n",
    "    (50, 0.5, 40, \"one_point\", \"inversion\", 15),\n",
    "    (50, 0.5, 40, \"uniform\", \"swap\", 5),\n",
    "    (50, 0.5, 40, \"uniform\", \"swap\", 10),\n",
    "    (50, 0.5, 40, \"uniform\", \"swap\", 15),\n",
    "    (50, 0.5, 40, \"uniform\", \"inversion\", 5),\n",
    "    (50, 0.5, 40, \"uniform\", \"inversion\", 10),\n",
    "    (50, 0.5, 40, \"uniform\", \"inversion\", 15),\n",
    "    (100, 0.1, 10, \"one_point\", \"swap\", 5),\n",
    "    (100, 0.1, 10, \"one_point\", \"swap\", 10),\n",
    "    (100, 0.1, 10, \"one_point\", \"swap\", 15),\n",
    "    (100, 0.1, 10, \"one_point\", \"inversion\", 5),\n",
    "    (100, 0.1, 10, \"one_point\", \"inversion\", 10),\n",
    "    (100, 0.1, 10, \"one_point\", \"inversion\", 15),\n",
    "    (100, 0.1, 10, \"uniform\", \"swap\", 5),\n",
    "    (100, 0.1, 10, \"uniform\", \"swap\", 10),\n",
    "    (100, 0.1, 10, \"uniform\", \"swap\", 15),\n",
    "    (100, 0.1, 10, \"uniform\", \"inversion\", 5),\n",
    "    (100, 0.1, 10, \"uniform\", \"inversion\", 10),\n",
    "    (100, 0.1, 10, \"uniform\", \"inversion\", 15),\n",
    "    (100, 0.1, 20, \"one_point\", \"swap\", 5),\n",
    "    (100, 0.1, 20, \"one_point\", \"swap\", 10),\n",
    "    (100, 0.1, 20, \"one_point\", \"swap\", 15),\n",
    "    (100, 0.1, 20, \"one_point\", \"inversion\", 5),\n",
    "    (100, 0.1, 20, \"one_point\", \"inversion\", 10),\n",
    "    (100, 0.1, 20, \"one_point\", \"inversion\", 15),\n",
    "    (100, 0.1, 20, \"uniform\", \"swap\", 5),\n",
    "    (100, 0.1, 20, \"uniform\", \"swap\", 10),\n",
    "    (100, 0.1, 20, \"uniform\", \"swap\", 15),\n",
    "    (100, 0.1, 20, \"uniform\", \"inversion\", 5),\n",
    "    (100, 0.1, 20, \"uniform\", \"inversion\", 10),\n",
    "    (100, 0.1, 20, \"uniform\", \"inversion\", 15),\n",
    "    (100, 0.1, 40, \"one_point\", \"swap\", 5),\n",
    "    (100, 0.1, 40, \"one_point\", \"swap\", 10),\n",
    "    (100, 0.1, 40, \"one_point\", \"swap\", 15),\n",
    "    (100, 0.1, 40, \"one_point\", \"inversion\", 5),\n",
    "    (100, 0.1, 40, \"one_point\", \"inversion\", 10),\n",
    "    (100, 0.1, 40, \"one_point\", \"inversion\", 15),\n",
    "    (100, 0.1, 40, \"uniform\", \"swap\", 5),\n",
    "    (100, 0.1, 40, \"uniform\", \"swap\", 10),\n",
    "    (100, 0.1, 40, \"uniform\", \"swap\", 15),\n",
    "    (100, 0.1, 40, \"uniform\", \"inversion\", 5),\n",
    "    (100, 0.1, 40, \"uniform\", \"inversion\", 10),\n",
    "    (100, 0.1, 40, \"uniform\", \"inversion\", 15),\n",
    "    (100, 0.5, 10, \"one_point\", \"swap\", 5),\n",
    "    (100, 0.5, 10, \"one_point\", \"swap\", 10),\n",
    "    (100, 0.5, 10, \"one_point\", \"swap\", 15),\n",
    "    (100, 0.5, 10, \"one_point\", \"inversion\", 5),\n",
    "    (100, 0.5, 10, \"one_point\", \"inversion\", 10),\n",
    "    (100, 0.5, 10, \"one_point\", \"inversion\", 15),\n",
    "    (100, 0.5, 10, \"uniform\", \"swap\", 5),\n",
    "    (100, 0.5, 10, \"uniform\", \"swap\", 10),\n",
    "    (100, 0.5, 10, \"uniform\", \"swap\", 15),\n",
    "    (100, 0.5, 10, \"uniform\", \"inversion\", 5),\n",
    "    (100, 0.5, 10, \"uniform\", \"inversion\", 10),\n",
    "    (100, 0.5, 10, \"uniform\", \"inversion\", 15),\n",
    "    (100, 0.5, 20, \"one_point\", \"swap\", 5),\n",
    "    (100, 0.5, 20, \"one_point\", \"swap\", 10),\n",
    "    (100, 0.5, 20, \"one_point\", \"swap\", 15),\n",
    "    (100, 0.5, 20, \"one_point\", \"inversion\", 5),\n",
    "    (100, 0.5, 20, \"one_point\", \"inversion\", 10),\n",
    "    (100, 0.5, 20, \"one_point\", \"inversion\", 15),\n",
    "    (100, 0.5, 20, \"uniform\", \"swap\", 5),\n",
    "    (100, 0.5, 20, \"uniform\", \"swap\", 10),\n",
    "    (100, 0.5, 20, \"uniform\", \"swap\", 15),\n",
    "    (100, 0.5, 20, \"uniform\", \"inversion\", 5),\n",
    "    (100, 0.5, 20, \"uniform\", \"inversion\", 10),\n",
    "    (100, 0.5, 20, \"uniform\", \"inversion\", 15),\n",
    "    (100, 0.5, 40, \"one_point\", \"swap\", 5),\n",
    "    (100, 0.5, 40, \"one_point\", \"swap\", 10),\n",
    "    (100, 0.5, 40, \"one_point\", \"swap\", 15),\n",
    "    (100, 0.5, 40, \"one_point\", \"inversion\", 5),\n",
    "    (100, 0.5, 40, \"one_point\", \"inversion\", 10),\n",
    "    (100, 0.5, 40, \"one_point\", \"inversion\", 15),\n",
    "    (100, 0.5, 40, \"uniform\", \"swap\", 5),\n",
    "    (100, 0.5, 40, \"uniform\", \"swap\", 10),\n",
    "    (100, 0.5, 40, \"uniform\", \"swap\", 15),\n",
    "    (100, 0.5, 40, \"uniform\", \"inversion\", 5),\n",
    "    (100, 0.5, 40, \"uniform\", \"inversion\", 10),\n",
    "    (100, 0.5, 40, \"uniform\", \"inversion\", 15),\n",
    "    (150, 0.1, 10, \"one_point\", \"swap\", 5),\n",
    "    (150, 0.1, 10, \"one_point\", \"swap\", 10),\n",
    "    (150, 0.1, 10, \"one_point\", \"swap\", 15),\n",
    "    (150, 0.1, 10, \"one_point\", \"inversion\", 5),\n",
    "    (150, 0.1, 10, \"one_point\", \"inversion\", 10),\n",
    "    (150, 0.1, 10, \"one_point\", \"inversion\", 15),\n",
    "    (150, 0.1, 10, \"uniform\", \"swap\", 5),\n",
    "    (150, 0.1, 10, \"uniform\", \"swap\", 10),\n",
    "    (150, 0.1, 10, \"uniform\", \"swap\", 15),\n",
    "    (150, 0.1, 10, \"uniform\", \"inversion\", 5),\n",
    "    (150, 0.1, 10, \"uniform\", \"inversion\", 10),\n",
    "    (150, 0.1, 10, \"uniform\", \"inversion\", 15),\n",
    "    (150, 0.1, 20, \"one_point\", \"swap\", 5),\n",
    "    (150, 0.1, 20, \"one_point\", \"swap\", 10),\n",
    "    (150, 0.1, 20, \"one_point\", \"swap\", 15),\n",
    "    (150, 0.1, 20, \"one_point\", \"inversion\", 5),\n",
    "    (150, 0.1, 20, \"one_point\", \"inversion\", 10),\n",
    "    (150, 0.1, 20, \"one_point\", \"inversion\", 15),\n",
    "    (150, 0.1, 20, \"uniform\", \"swap\", 5),\n",
    "    (150, 0.1, 20, \"uniform\", \"swap\", 10),\n",
    "    (150, 0.1, 20, \"uniform\", \"swap\", 15),\n",
    "    (150, 0.1, 20, \"uniform\", \"inversion\", 5),\n",
    "    (150, 0.1, 20, \"uniform\", \"inversion\", 10),\n",
    "    (150, 0.1, 20, \"uniform\", \"inversion\", 15),\n",
    "    (150, 0.1, 40, \"one_point\", \"swap\", 5),\n",
    "    (150, 0.1, 40, \"one_point\", \"swap\", 10),\n",
    "    (150, 0.1, 40, \"one_point\", \"swap\", 15),\n",
    "    (150, 0.1, 40, \"one_point\", \"inversion\", 5),\n",
    "    (150, 0.1, 40, \"one_point\", \"inversion\", 10),\n",
    "    (150, 0.1, 40, \"one_point\", \"inversion\", 15),\n",
    "    (150, 0.1, 40, \"uniform\", \"swap\", 5),\n",
    "    (150, 0.1, 40, \"uniform\", \"swap\", 10),\n",
    "    (150, 0.1, 40, \"uniform\", \"swap\", 15),\n",
    "    (150, 0.1, 40, \"uniform\", \"inversion\", 5),\n",
    "    (150, 0.1, 40, \"uniform\", \"inversion\", 10),\n",
    "    (150, 0.1, 40, \"uniform\", \"inversion\", 15),\n",
    "    (150, 0.5, 10, \"one_point\", \"swap\", 5),\n",
    "    (150, 0.5, 10, \"one_point\", \"swap\", 10),\n",
    "    (150, 0.5, 10, \"one_point\", \"swap\", 15),\n",
    "    (150, 0.5, 10, \"one_point\", \"inversion\", 5),\n",
    "    (150, 0.5, 10, \"one_point\", \"inversion\", 10),\n",
    "    (150, 0.5, 10, \"one_point\", \"inversion\", 15),\n",
    "    (150, 0.5, 10, \"uniform\", \"swap\", 5),\n",
    "    (150, 0.5, 10, \"uniform\", \"swap\", 10),\n",
    "    (150, 0.5, 10, \"uniform\", \"swap\", 15),\n",
    "    (150, 0.5, 10, \"uniform\", \"inversion\", 5),\n",
    "    (150, 0.5, 10, \"uniform\", \"inversion\", 10),\n",
    "    (150, 0.5, 10, \"uniform\", \"inversion\", 15),\n",
    "    (150, 0.5, 20, \"one_point\", \"swap\", 5),\n",
    "    (150, 0.5, 20, \"one_point\", \"swap\", 10),\n",
    "    (150, 0.5, 20, \"one_point\", \"swap\", 15),\n",
    "    (150, 0.5, 20, \"one_point\", \"inversion\", 5),\n",
    "    (150, 0.5, 20, \"one_point\", \"inversion\", 10),\n",
    "    (150, 0.5, 20, \"one_point\", \"inversion\", 15),\n",
    "    (150, 0.5, 20, \"uniform\", \"swap\", 5),\n",
    "    (150, 0.5, 20, \"uniform\", \"swap\", 10),\n",
    "    (150, 0.5, 20, \"uniform\", \"swap\", 15),\n",
    "    (150, 0.5, 20, \"uniform\", \"inversion\", 5),\n",
    "    (150, 0.5, 20, \"uniform\", \"inversion\", 10),\n",
    "    (150, 0.5, 20, \"uniform\", \"inversion\", 15),\n",
    "    (150, 0.5, 40, \"one_point\", \"swap\", 5),\n",
    "    (150, 0.5, 40, \"one_point\", \"swap\", 10),\n",
    "    (150, 0.5, 40, \"one_point\", \"swap\", 15),\n",
    "    (150, 0.5, 40, \"one_point\", \"inversion\", 5),\n",
    "    (150, 0.5, 40, \"one_point\", \"inversion\", 10),\n",
    "    (150, 0.5, 40, \"one_point\", \"inversion\", 15),\n",
    "    (150, 0.5, 40, \"uniform\", \"swap\", 5),\n",
    "    (150, 0.5, 40, \"uniform\", \"swap\", 10),\n",
    "    (150, 0.5, 40, \"uniform\", \"swap\", 15),\n",
    "    (150, 0.5, 40, \"uniform\", \"inversion\", 5),\n",
    "    (150, 0.5, 40, \"uniform\", \"inversion\", 10),\n",
    "    (150, 0.5, 40, \"uniform\", \"inversion\", 15),\n",
    "    (200, 0.1, 10, \"one_point\", \"swap\", 5),\n",
    "    (200, 0.1, 10, \"one_point\", \"swap\", 10),\n",
    "    (200, 0.1, 10, \"one_point\", \"swap\", 15),\n",
    "    (200, 0.1, 10, \"one_point\", \"inversion\", 5),\n",
    "    (200, 0.1, 10, \"one_point\", \"inversion\", 10),\n",
    "    (200, 0.1, 10, \"one_point\", \"inversion\", 15),\n",
    "    (200, 0.1, 10, \"uniform\", \"swap\", 5),\n",
    "    (200, 0.1, 10, \"uniform\", \"swap\", 10),\n",
    "    (200, 0.1, 10, \"uniform\", \"swap\", 15),\n",
    "    (200, 0.1, 10, \"uniform\", \"inversion\", 5),\n",
    "    (200, 0.1, 10, \"uniform\", \"inversion\", 10),\n",
    "    (200, 0.1, 10, \"uniform\", \"inversion\", 15),\n",
    "    (200, 0.1, 20, \"one_point\", \"swap\", 5),\n",
    "    (200, 0.1, 20, \"one_point\", \"swap\", 10),\n",
    "    (200, 0.1, 20, \"one_point\", \"swap\", 15),\n",
    "    (200, 0.1, 20, \"one_point\", \"inversion\", 5),\n",
    "    (200, 0.1, 20, \"one_point\", \"inversion\", 10),\n",
    "    (200, 0.1, 20, \"one_point\", \"inversion\", 15),\n",
    "    (200, 0.1, 20, \"uniform\", \"swap\", 5),\n",
    "    (200, 0.1, 20, \"uniform\", \"swap\", 10),\n",
    "    (200, 0.1, 20, \"uniform\", \"swap\", 15),\n",
    "    (200, 0.1, 20, \"uniform\", \"inversion\", 5),\n",
    "    (200, 0.1, 20, \"uniform\", \"inversion\", 10),\n",
    "    (200, 0.1, 20, \"uniform\", \"inversion\", 15),\n",
    "    (200, 0.1, 40, \"one_point\", \"swap\", 5),\n",
    "    (200, 0.1, 40, \"one_point\", \"swap\", 10),\n",
    "    (200, 0.1, 40, \"one_point\", \"swap\", 15),\n",
    "    (200, 0.1, 40, \"one_point\", \"inversion\", 5),\n",
    "    (200, 0.1, 40, \"one_point\", \"inversion\", 10),\n",
    "    (200, 0.1, 40, \"one_point\", \"inversion\", 15),\n",
    "    (200, 0.1, 40, \"uniform\", \"swap\", 5),\n",
    "    (200, 0.1, 40, \"uniform\", \"swap\", 10),\n",
    "    (200, 0.1, 40, \"uniform\", \"swap\", 15),\n",
    "    (200, 0.1, 40, \"uniform\", \"inversion\", 5),\n",
    "    (200, 0.1, 40, \"uniform\", \"inversion\", 10),\n",
    "    (200, 0.1, 40, \"uniform\", \"inversion\", 15),\n",
    "    (200, 0.5, 10, \"one_point\", \"swap\", 5),\n",
    "    (200, 0.5, 10, \"one_point\", \"swap\", 10),\n",
    "    (200, 0.5, 10, \"one_point\", \"swap\", 15),\n",
    "    (200, 0.5, 10, \"one_point\", \"inversion\", 5),\n",
    "    (200, 0.5, 10, \"one_point\", \"inversion\", 10),\n",
    "    (200, 0.5, 10, \"one_point\", \"inversion\", 15),\n",
    "    (200, 0.5, 10, \"uniform\", \"swap\", 5),\n",
    "    (200, 0.5, 10, \"uniform\", \"swap\", 10),\n",
    "    (200, 0.5, 10, \"uniform\", \"swap\", 15),\n",
    "    (200, 0.5, 10, \"uniform\", \"inversion\", 5),\n",
    "    (200, 0.5, 10, \"uniform\", \"inversion\", 10),\n",
    "    (200, 0.5, 10, \"uniform\", \"inversion\", 15),\n",
    "    (200, 0.5, 20, \"one_point\", \"swap\", 5),\n",
    "    (200, 0.5, 20, \"one_point\", \"swap\", 10),\n",
    "    (200, 0.5, 20, \"one_point\", \"swap\", 15),\n",
    "    (200, 0.5, 20, \"one_point\", \"inversion\", 5),\n",
    "    (200, 0.5, 20, \"one_point\", \"inversion\", 10),\n",
    "    (200, 0.5, 20, \"one_point\", \"inversion\", 15),\n",
    "    (200, 0.5, 20, \"uniform\", \"swap\", 5),\n",
    "    (200, 0.5, 20, \"uniform\", \"swap\", 10),\n",
    "    (200, 0.5, 20, \"uniform\", \"swap\", 15),\n",
    "    (200, 0.5, 20, \"uniform\", \"inversion\", 5),\n",
    "    (200, 0.5, 20, \"uniform\", \"inversion\", 10),\n",
    "    (200, 0.5, 20, \"uniform\", \"inversion\", 15),\n",
    "    (200, 0.5, 40, \"one_point\", \"swap\", 5),\n",
    "    (200, 0.5, 40, \"one_point\", \"swap\", 10),\n",
    "    (200, 0.5, 40, \"one_point\", \"swap\", 15),\n",
    "    (200, 0.5, 40, \"one_point\", \"inversion\", 5),\n",
    "    (200, 0.5, 40, \"one_point\", \"inversion\", 10),\n",
    "    (200, 0.5, 40, \"one_point\", \"inversion\", 15),\n",
    "    (200, 0.5, 40, \"uniform\", \"swap\", 5),\n",
    "    (200, 0.5, 40, \"uniform\", \"swap\", 10),\n",
    "    (200, 0.5, 40, \"uniform\", \"swap\", 15),\n",
    "    (200, 0.5, 40, \"uniform\", \"inversion\", 5),\n",
    "    (200, 0.5, 40, \"uniform\", \"inversion\", 10),\n",
    "    (200, 0.5, 40, \"uniform\", \"inversion\", 15),\n",
    "    # Add more combinations here if needed\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 60/262 [4:12:51<14:11:18, 252.87s/it]  \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'filename' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 18\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39m# Call the genetic_algorithm method with appropriate arguments\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m best_solution, semratings_dict, fitness_scores_dict, best_solutions_by_generation \u001b[39m=\u001b[39m recommender\u001b[39m.\u001b[39;49mgenetic_algorithm(\n\u001b[0;32m     19\u001b[0m     pop_size, mutation_rate, num_generations, crossover_func, mutation_func, no_rec\n\u001b[0;32m     20\u001b[0m )\n\u001b[0;32m     22\u001b[0m \u001b[39m# Append the results to the list\u001b[39;00m\n",
      "File \u001b[1;32md:\\PROJECTS\\Github\\book-recommender-using-cf-and-ga\\Final Algorithm\\Book Recommender\\bliga.py:245\u001b[0m, in \u001b[0;36mBookRecommendationSystem.genetic_algorithm\u001b[1;34m(self, pop_size, mutation_rate, num_generations, crossover_func, mutation_func, no_rec)\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[39mif\u001b[39;00m tuple_solution \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m fitness_scores_dict:\n\u001b[1;32m--> 245\u001b[0m     total_predicted_rating, predicted_rating_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcalculate_total_rating(tuple_solution)\n\u001b[0;32m    246\u001b[0m     fitness_scores_dict[tuple_solution] \u001b[39m=\u001b[39m {\n\u001b[0;32m    247\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtotal_predicted_rating\u001b[39m\u001b[39m\"\u001b[39m: total_predicted_rating,\n\u001b[0;32m    248\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpredicted_rating_list\u001b[39m\u001b[39m\"\u001b[39m: predicted_rating_list\n\u001b[0;32m    249\u001b[0m     }\n",
      "File \u001b[1;32md:\\PROJECTS\\Github\\book-recommender-using-cf-and-ga\\Final Algorithm\\Book Recommender\\bliga.py:76\u001b[0m, in \u001b[0;36mBookRecommendationSystem.calculate_total_rating\u001b[1;34m(self, solution)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[39mfor\u001b[39;00m item_index \u001b[39min\u001b[39;00m solution:\n\u001b[1;32m---> 76\u001b[0m     predicted_rating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcalculate_predicted_rating_aws(item_index)\n\u001b[0;32m     77\u001b[0m     total_predicted_rating \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m predicted_rating\n",
      "File \u001b[1;32md:\\PROJECTS\\Github\\book-recommender-using-cf-and-ga\\Final Algorithm\\Book Recommender\\bliga.py:87\u001b[0m, in \u001b[0;36mBookRecommendationSystem.calculate_predicted_rating_aws\u001b[1;34m(self, target_item_index)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[39mif\u001b[39;00m user_rating[target_item_index] \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m---> 87\u001b[0m     pearson_similarity \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpearson_similarity(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49muser_ratings_input, user_rating)\n\u001b[0;32m     88\u001b[0m     jaccard_coefficient \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjaccard_coefficient(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39muser_ratings_input, user_rating)\n",
      "File \u001b[1;32md:\\PROJECTS\\Github\\book-recommender-using-cf-and-ga\\Final Algorithm\\Book Recommender\\bliga.py:103\u001b[0m, in \u001b[0;36mBookRecommendationSystem.pearson_similarity\u001b[1;34m(self, a, b)\u001b[0m\n\u001b[0;32m    102\u001b[0m b_mean \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(b)\n\u001b[1;32m--> 103\u001b[0m numerator \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum((a \u001b[39m-\u001b[39m a_mean) \u001b[39m*\u001b[39m (b \u001b[39m-\u001b[39;49m b_mean))\n\u001b[0;32m    104\u001b[0m denominator \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msqrt(np\u001b[39m.\u001b[39msum((a \u001b[39m-\u001b[39m a_mean)\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m) \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39msum((b \u001b[39m-\u001b[39m b_mean)\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 41\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m     \u001b[39m# If the script is interrupted (Ctrl+C), save the results collected so far to the same file\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     results_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(results_list, columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mPopulation Size\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMutation Rate\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mNumber of Generations\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mCrossover Function\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMutation Function\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mNo. of Recommendations\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mBest Solution\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mSemratings Dictionary\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mFitness Scores Dict\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mBest Solution By Generation\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m---> 41\u001b[0m     results_df\u001b[39m.\u001b[39mto_excel(filename, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'filename' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "# Define your genetic algorithm function here (genetic_algorithm_function)\n",
    "\n",
    "filename = 'results.xlsx'\n",
    "results_list = []  # Initialize the results_list before the loop\n",
    "\n",
    "try:\n",
    "    # Use tqdm to create a progress bar\n",
    "    for i in tqdm(range(26, len(combinations_list))):\n",
    "        combo = combinations_list[i]\n",
    "        pop_size, mutation_rate, num_generations, crossover_func, mutation_func, no_rec = combinations_list[i]\n",
    "\n",
    "        try:\n",
    "            # Using BookRecommendationSystem\n",
    "            recommender = BookRecommendationSystem(user_ratings_input, user_ratings, semantic)\n",
    "\n",
    "            # Call the genetic_algorithm method with appropriate arguments\n",
    "            best_solution, semratings_dict, fitness_scores_dict, best_solutions_by_generation = recommender.genetic_algorithm(\n",
    "                pop_size, mutation_rate, num_generations, crossover_func, mutation_func, no_rec\n",
    "            )\n",
    "\n",
    "            # Append the results to the list\n",
    "            results_list.append((pop_size, mutation_rate, num_generations, crossover_func, mutation_func, no_rec, best_solution, semratings_dict, fitness_scores_dict, best_solutions_by_generation))\n",
    "\n",
    "        except Exception as e:\n",
    "            # Handle any errors that occur during execution\n",
    "            print(f\"Error occurred for combination: {combo}. Error message: {str(e)}\")\n",
    "\n",
    "# The loop has finished; results are already collected\n",
    "\n",
    "finally:\n",
    "    # Check if the file already exists\n",
    "    if os.path.exists(filename):\n",
    "        raise FileExistsError(f\"File '{filename}' already exists. Choose a different filename or delete the existing file.\")\n",
    "    else:\n",
    "        results_df = pd.DataFrame(results_list, columns=['Population Size', 'Mutation Rate', 'Number of Generations', 'Crossover Function', 'Mutation Function', 'No. of Recommendations', 'Best Solution', 'Semratings Dictionary', 'Fitness Scores Dict', 'Best Solution By Generation'])\n",
    "\n",
    "        # Save the DataFrame to the unique filename\n",
    "        results_df.to_excel(filename, index=False)\n",
    "        print(\"Results saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Population Size  Mutation Rate  Number of Generations Crossover Function  \\\n",
      "0                 50            0.1                     40          one_point   \n",
      "1                 50            0.1                     40          one_point   \n",
      "2                 50            0.1                     40          one_point   \n",
      "3                 50            0.1                     40          one_point   \n",
      "4                 50            0.1                     40            uniform   \n",
      "..               ...            ...                    ...                ...   \n",
      "130              150            0.1                     20          one_point   \n",
      "131              150            0.1                     20          one_point   \n",
      "132              150            0.1                     20          one_point   \n",
      "133              150            0.1                     20          one_point   \n",
      "134              150            0.1                     20          one_point   \n",
      "\n",
      "    Mutation Function  No. of Recommendations  \\\n",
      "0                swap                      15   \n",
      "1           inversion                       5   \n",
      "2           inversion                      10   \n",
      "3           inversion                      15   \n",
      "4                swap                       5   \n",
      "..                ...                     ...   \n",
      "130              swap                       5   \n",
      "131              swap                      10   \n",
      "132              swap                      15   \n",
      "133         inversion                       5   \n",
      "134         inversion                      10   \n",
      "\n",
      "                                         Best Solution  Unnamed: 7  \\\n",
      "0    (167, 84, 54, 164, 73, 145, 34, 143, 147, 89, ...         NaN   \n",
      "1                              (88, 123, 143, 147, 72)         NaN   \n",
      "2       (145, 173, 143, 123, 17, 117, 76, 147, 89, 72)         NaN   \n",
      "3    (34, 158, 76, 123, 147, 145, 100, 173, 167, 14...         NaN   \n",
      "4                             (147, 145, 143, 167, 76)         NaN   \n",
      "..                                                 ...         ...   \n",
      "130                           (143, 173, 72, 147, 167)         NaN   \n",
      "131      (73, 143, 72, 147, 145, 89, 76, 167, 47, 173)         NaN   \n",
      "132  (147, 106, 17, 40, 164, 89, 73, 167, 72, 123, ...         NaN   \n",
      "133                            (147, 76, 167, 72, 143)         NaN   \n",
      "134  [164, 88, 106, 143, 147, 173, 167, 134, 158, 135]         NaN   \n",
      "\n",
      "                                 Semratings Dictionary  \\\n",
      "0    {(38, 17, 23, 145, 76, 92, 117, 72, 197, 123, ...   \n",
      "1    {(73, 84, 147, 145, 92): 0.1111111111111111, (...   \n",
      "2    {(167, 100, 123, 134, 54, 76, 145, 89, 197, 84...   \n",
      "3    {(29, 164, 167, 117, 145, 47, 197, 72, 100, 23...   \n",
      "4    {(89, 73, 106, 88, 84): 0.02127659574468085, (...   \n",
      "..                                                 ...   \n",
      "130  {(143, 38, 158, 47, 106): 0.2, (136, 34, 123, ...   \n",
      "131  {(54, 29, 89, 40, 164, 147, 73, 88, 17, 92): 0...   \n",
      "132  {(158, 84, 23, 47, 89, 147, 117, 106, 34, 38, ...   \n",
      "133  {(134, 135, 117, 88, 34): 0.0196078431372549, ...   \n",
      "134  {(197, 164, 117, 135, 106, 38, 17, 72, 54, 88)...   \n",
      "\n",
      "                                   Fitness Scores Dict  \\\n",
      "0    {(167, 47, 38, 54, 100, 143, 117, 173, 145, 13...   \n",
      "1    {(88, 23, 76, 106, 72): {'total_predicted_rati...   \n",
      "2    {(17, 54, 73, 164, 88, 123, 106, 143, 173, 34)...   \n",
      "3    {(47, 88, 29, 123, 38, 92, 145, 34, 40, 147, 8...   \n",
      "4    {(167, 173, 38, 88, 34): {'total_predicted_rat...   \n",
      "..                                                 ...   \n",
      "130  {(123, 29, 145, 76, 47): {'total_predicted_rat...   \n",
      "131  {(143, 17, 197, 89, 72, 136, 29, 76, 164, 147)...   \n",
      "132  {(34, 92, 89, 158, 136, 38, 106, 134, 40, 54, ...   \n",
      "133  {(158, 197, 88, 38, 89): {'total_predicted_rat...   \n",
      "134  {(167, 47, 100, 106, 84, 147, 88, 38, 92, 143)...   \n",
      "\n",
      "                           Best Solution By Generation  \n",
      "0    {0: (135, 143, 92, 167, 76, 147, 197, 106, 117...  \n",
      "1    {0: [145, 164, 143, 123, 88], 1: [145, 123, 14...  \n",
      "2    {0: [76, 117, 84, 147, 158, 167, 89, 88, 197, ...  \n",
      "3    {0: [117, 167, 106, 100, 34, 72, 17, 47, 164, ...  \n",
      "4    {0: (143, 76, 88, 167, 23), 1: (143, 76, 88, 1...  \n",
      "..                                                 ...  \n",
      "130  {0: (88, 73, 92, 76, 143), 1: (143, 88, 158, 1...  \n",
      "131  {0: (164, 173, 100, 123, 17, 145, 143, 106, 73...  \n",
      "132  {0: (164, 88, 123, 143, 34, 84, 92, 167, 76, 1...  \n",
      "133  {0: [147, 34, 72, 76, 143], 1: [147, 72, 197, ...  \n",
      "134  {0: [147, 158, 40, 143, 100, 76, 88, 167, 134,...  \n",
      "\n",
      "[135 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "current = os.getcwd()\n",
    "# Replace 'your_file_path.xlsx' with the actual path to your Excel file\n",
    "file_path = 'checkpoint_160.xlsx'\n",
    "\n",
    "file = os.path.join(current,file_path)\n",
    "\n",
    "# Read the Excel file into a pandas DataFrame\n",
    "df = pd.read_excel(file)\n",
    "\n",
    "# Display the DataFrame to see its contents\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      (167, 84, 54, 164, 73, 145, 34, 143, 147, 89, ...\n",
      "1                                (88, 123, 143, 147, 72)\n",
      "2         (145, 173, 143, 123, 17, 117, 76, 147, 89, 72)\n",
      "3      (34, 158, 76, 123, 147, 145, 100, 173, 167, 14...\n",
      "4                               (147, 145, 143, 167, 76)\n",
      "                             ...                        \n",
      "130                             (143, 173, 72, 147, 167)\n",
      "131        (73, 143, 72, 147, 145, 89, 76, 167, 47, 173)\n",
      "132    (147, 106, 17, 40, 164, 89, 73, 167, 72, 123, ...\n",
      "133                              (147, 76, 167, 72, 143)\n",
      "134    [164, 88, 106, 143, 147, 173, 167, 134, 158, 135]\n",
      "Name: Best Solution, Length: 135, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you have already read the Excel file into the 'df' DataFrame\n",
    "# If not, read the Excel file as before:\n",
    "# df = pd.read_excel(file_path)\n",
    "\n",
    "# Access the row at index 7 using iloc\n",
    "# Access the column using the column integer index (6 for column 7)\n",
    "best_solution = df.iloc[:, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      (167, 84, 54, 164, 73, 145, 34, 143, 147, 89, ...\n",
       "1                                (88, 123, 143, 147, 72)\n",
       "2         (145, 173, 143, 123, 17, 117, 76, 147, 89, 72)\n",
       "3      (34, 158, 76, 123, 147, 145, 100, 173, 167, 14...\n",
       "4                               (147, 145, 143, 167, 76)\n",
       "                             ...                        \n",
       "130                             (143, 173, 72, 147, 167)\n",
       "131        (73, 143, 72, 147, 145, 89, 76, 167, 47, 173)\n",
       "132    (147, 106, 17, 40, 164, 89, 73, 167, 72, 123, ...\n",
       "133                              (147, 76, 167, 72, 143)\n",
       "134    [164, 88, 106, 143, 147, 173, 167, 134, 158, 135]\n",
       "Name: Best Solution, Length: 135, dtype: object"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_solution_list = df.iloc[:, 6]\n",
    "best_solution_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      {(38, 17, 23, 145, 76, 92, 117, 72, 197, 123, ...\n",
      "1      {(73, 84, 147, 145, 92): 0.1111111111111111, (...\n",
      "2      {(167, 100, 123, 134, 54, 76, 145, 89, 197, 84...\n",
      "3      {(29, 164, 167, 117, 145, 47, 197, 72, 100, 23...\n",
      "4      {(89, 73, 106, 88, 84): 0.02127659574468085, (...\n",
      "                             ...                        \n",
      "130    {(143, 38, 158, 47, 106): 0.2, (136, 34, 123, ...\n",
      "131    {(54, 29, 89, 40, 164, 147, 73, 88, 17, 92): 0...\n",
      "132    {(158, 84, 23, 47, 89, 147, 117, 106, 34, 38, ...\n",
      "133    {(134, 135, 117, 88, 34): 0.0196078431372549, ...\n",
      "134    {(197, 164, 117, 135, 106, 38, 17, 72, 54, 88)...\n",
      "Name: Semratings Dictionary, Length: 135, dtype: object\n"
     ]
    }
   ],
   "source": [
    "semratings_dict_list = df.iloc[:,8]\n",
    "print(semratings_dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      {(167, 47, 38, 54, 100, 143, 117, 173, 145, 13...\n",
      "1      {(88, 23, 76, 106, 72): {'total_predicted_rati...\n",
      "2      {(17, 54, 73, 164, 88, 123, 106, 143, 173, 34)...\n",
      "3      {(47, 88, 29, 123, 38, 92, 145, 34, 40, 147, 8...\n",
      "4      {(167, 173, 38, 88, 34): {'total_predicted_rat...\n",
      "                             ...                        \n",
      "130    {(123, 29, 145, 76, 47): {'total_predicted_rat...\n",
      "131    {(143, 17, 197, 89, 72, 136, 29, 76, 164, 147)...\n",
      "132    {(34, 92, 89, 158, 136, 38, 106, 134, 40, 54, ...\n",
      "133    {(158, 197, 88, 38, 89): {'total_predicted_rat...\n",
      "134    {(167, 47, 100, 106, 84, 147, 88, 38, 92, 143)...\n",
      "Name: Fitness Scores Dict, Length: 135, dtype: object\n"
     ]
    }
   ],
   "source": [
    "fitness_scores_dict_list = df.iloc[:,9]\n",
    "print(fitness_scores_dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{(197, 164, 117, 135, 106, 38, 17, 72, 54, 88): 0.2625, (17, 143, 123, 135, 136, 147, 76, 72, 197, 23): 1.0, (23, 89, 106, 88, 100, 92, 76, 136, 164, 38): 0.2791666666666667, (135, 47, 134, 145, 136, 106, 197, 92, 143, 23): 0.20202020202020202, (100, 89, 173, 84, 158, 106, 197, 167, 164, 92): 0.5, (34, 143, 17, 145, 88, 100, 158, 89, 167, 123): 0.667755991285403, (73, 197, 47, 123, 23, 117, 40, 88, 84, 147): 0.02127659574468085, (164, 47, 89, 123, 147, 72, 117, 84, 106, 135): 1.0, (147, 158, 73, 38, 40, 17, 145, 54, 92, 117): 0.1111111111111111, (134, 100, 145, 84, 117, 72, 88, 173, 17, 106): 0.037037037037037035, (72, 38, 47, 106, 117, 173, 123, 89, 76, 40): 0.2, (84, 17, 76, 92, 145, 100, 136, 143, 106, 173): 0.1111111111111111, (173, 197, 76, 47, 88, 106, 123, 17, 34, 134): 0.09183006535947712, (88, 72, 167, 123, 143, 47, 158, 147, 23, 135): 1.0, (38, 167, 88, 23, 92, 173, 135, 164, 84, 29): 0.0625, (40, 89, 145, 17, 84, 76, 34, 147, 100, 123): 0.05555555555555555, (147, 143, 197, 134, 47, 145, 84, 117, 76, 92): 0.20202020202020202, (40, 143, 88, 89, 76, 158, 17, 72, 145, 47): 0.6446127946127946, (84, 40, 88, 117, 164, 197, 167, 89, 100, 29): 0.0625, (123, 92, 197, 136, 47, 34, 38, 76, 23, 173): 0.05555555555555555, (134, 173, 167, 117, 136, 73, 145, 197, 34, 123): 0.1111111111111111, (100, 88, 40, 147, 47, 123, 145, 158, 167, 72): 1.239057239057239, (84, 34, 100, 173, 88, 54, 47, 17, 92, 23): 0.0196078431372549, (167, 29, 17, 135, 72, 34, 164, 84, 76, 54): 0.05555555555555555, (29, 84, 88, 17, 143, 164, 134, 89, 23, 197): 0.0625, (73, 72, 164, 84, 47, 147, 123, 117, 167, 54): 1.0, (197, 40, 29, 158, 173, 147, 34, 38, 88, 89): 0.5196078431372549, (34, 29, 84, 38, 117, 88, 17, 136, 92, 173): 0.0196078431372549, (89, 117, 38, 164, 158, 73, 197, 23, 173, 84): 0.5, (136, 164, 17, 147, 145, 106, 84, 167, 197, 92): 0.2222222222222222, (145, 73, 158, 47, 88, 197, 40, 123, 34, 143): 0.1688305668280637, (106, 134, 34, 88, 84, 145, 47, 17, 38, 23): 0.3475539710833828, (145, 92, 89, 164, 17, 135, 47, 23, 143, 40): 0.20202020202020202, (88, 145, 47, 197, 54, 136, 134, 23, 158, 73): 0.1492227236908088, (54, 164, 135, 143, 17, 167, 134, 92, 145, 117): 0.2222222222222222, (173, 92, 38, 34, 143, 158, 136, 72, 88, 100): 0.0196078431372549, (76, 123, 117, 145, 72, 29, 88, 47, 34, 136): 0.21977619330560505, (76, 134, 164, 145, 167, 143, 40, 197, 100, 136): 0.1111111111111111, (100, 47, 134, 147, 23, 54, 92, 34, 73, 76): 0.05555555555555555, (29, 145, 158, 100, 73, 84, 76, 89, 38, 72): 0.5, (106, 84, 88, 134, 135, 54, 100, 158, 38, 76): 0.21666666666666667, (34, 145, 88, 136, 73, 100, 164, 117, 54, 134): 0.1404214759189728, (158, 92, 47, 117, 17, 147, 106, 173, 135, 72): 1.0, (136, 88, 164, 76, 38, 167, 54, 135, 72, 34): 0.15433006535947713, (117, 34, 54, 72, 84, 158, 89, 164, 143, 88): 0.5821078431372549, (73, 117, 167, 106, 88, 145, 147, 38, 197, 143): 0.36942474389282903, (38, 76, 135, 34, 134, 143, 158, 106, 173, 145): 0.25555555555555554, (34, 54, 73, 135, 38, 89, 123, 197, 167, 88): 0.040884438881935756, (38, 164, 47, 54, 88, 147, 34, 117, 158, 136): 0.0821078431372549, (92, 17, 100, 123, 38, 106, 136, 88, 84, 47): 0.2, (73, 134, 100, 76, 158, 143, 23, 34, 135, 117): 0.05555555555555555, (134, 72, 23, 167, 47, 145, 38, 197, 143, 89): 0.20202020202020202, (145, 38, 47, 54, 29, 173, 164, 167, 136, 89): 0.20202020202020202, (123, 135, 34, 47, 167, 145, 134, 40, 72, 136): 0.20202020202020202, (29, 135, 38, 76, 47, 145, 134, 164, 17, 92): 0.20202020202020202, (135, 76, 84, 117, 38, 147, 136, 34, 17, 167): 0.05555555555555555, (38, 73, 134, 34, 76, 47, 92, 123, 89, 164): 0.05555555555555555, (135, 54, 134, 76, 167, 23, 72, 88, 29, 100): 0.016666666666666666, (47, 38, 197, 158, 143, 84, 117, 40, 106, 136): 0.2, (117, 134, 89, 34, 106, 38, 92, 143, 47, 84): 0.2, (54, 100, 135, 89, 40, 76, 123, 34, 143, 23): 0.05555555555555555, (145, 143, 17, 54, 34, 164, 167, 158, 47, 89): 0.702020202020202, (92, 76, 134, 89, 135, 38, 72, 147, 17, 167): 1.0, (54, 29, 17, 47, 76, 167, 88, 143, 145, 158): 0.2557239057239057, (147, 89, 134, 40, 73, 106, 47, 38, 88, 84): 0.22127659574468087, (147, 23, 76, 92, 136, 72, 47, 158, 123, 197): 1.0, (47, 158, 40, 143, 100, 76, 88, 167, 134, 106): 0.016666666666666666, (164, 88, 106, 143, 123, 47, 117, 158, 197, 173): 0.0625, (34, 72, 73, 106, 40, 17, 76, 84, 143, 29): 0.05555555555555555, (147, 40, 164, 158, 84, 143, 76, 17, 88, 136): 0.07916666666666666, (158, 100, 197, 38, 135, 92, 117, 134, 145, 76): 0.1111111111111111, (38, 88, 34, 89, 92, 173, 40, 17, 54, 72): 0.0196078431372549, (147, 72, 54, 134, 84, 136, 135, 47, 145, 73): 1.0909090909090908, (117, 34, 89, 164, 106, 47, 76, 23, 92, 173): 0.05555555555555555, (147, 88, 17, 92, 136, 23, 100, 40, 34, 117): 0.0196078431372549, (136, 92, 84, 73, 29, 135, 88, 40, 34, 72): 0.040884438881935756, (164, 135, 40, 23, 34, 167, 89, 29, 100, 76): 0.05555555555555555, (73, 92, 136, 134, 167, 38, 47, 106, 117, 89): 0.2, (17, 167, 135, 136, 100, 38, 23, 89, 106, 40): 0.2, (34, 88, 73, 158, 123, 135, 100, 72, 164, 143): 0.10338443888193576, (38, 40, 135, 167, 88, 123, 173, 92, 73, 158): 0.02127659574468085, (167, 34, 134, 100, 173, 117, 88, 47, 40, 72): 0.0196078431372549, (164, 147, 123, 34, 135, 89, 167, 29, 136, 145): 0.1111111111111111, (100, 197, 47, 173, 84, 123, 88, 76, 134, 23): 0.016666666666666666, (84, 76, 88, 147, 89, 54, 100, 158, 73, 38): 0.5379432624113475, (29, 76, 92, 34, 100, 106, 23, 89, 47, 40): 0.05555555555555555, (173, 106, 164, 145, 34, 100, 84, 147, 47, 23): 0.09090909090909091, (47, 147, 134, 117, 89, 158, 23, 73, 40, 106): 0.5, (147, 76, 117, 38, 106, 40, 84, 136, 47, 73): 0.2, (23, 135, 73, 100, 29, 164, 92, 173, 145, 47): 0.20202020202020202, (23, 92, 72, 143, 147, 173, 167, 134, 158, 135): 1.0, (89, 84, 73, 143, 106, 29, 17, 23, 158, 47): 0.5, (106, 145, 147, 164, 72, 117, 143, 38, 73, 84): 1.2, (106, 17, 54, 76, 38, 135, 173, 72, 147, 100): 1.2, (17, 164, 135, 38, 158, 23, 173, 106, 40, 136): 0.2, (100, 17, 117, 147, 23, 173, 40, 164, 72, 106): 1.0, (197, 34, 147, 117, 135, 89, 38, 134, 17, 72): 1.0, (84, 72, 38, 88, 34, 76, 117, 54, 29, 158): 0.09183006535947712, (164, 89, 135, 34, 197, 100, 158, 84, 117, 136): 0.5, (40, 38, 136, 147, 158, 88, 17, 117, 145, 100): 0.037037037037037035, (88, 173, 29, 38, 145, 197, 143, 135, 92, 40): 0.14814814814814814, (76, 92, 143, 167, 136, 73, 34, 17, 158, 173): 0.05555555555555555, (164, 47, 123, 158, 100, 38, 88, 167, 136, 89): 0.5625, (88, 164, 106, 143, 123, 47, 117, 84, 29): 0.0625, (34, 72, 197, 158, 76, 17, 40, 106, 73, 173): 0.05555555555555555, (23, 89, 106, 88, 100, 92, 167, 76, 164): 0.07916666666666666, (100, 89, 173, 84, 158, 164, 136, 197, 106, 38): 0.7, (34, 145, 72, 100, 73, 136, 88): 0.07792147591897279, (73, 143, 158, 100, 88, 145, 17, 89, 167, 123): 0.6694247438928291, (34, 117, 167, 106, 88, 145, 147, 38, 197, 143): 0.36775599128540304, (145, 38, 47, 29, 54, 173, 164, 167, 136, 89): 0.20202020202020202, (173, 197, 76, 134, 34, 17, 123, 106, 88, 47): 0.09183006535947712, (40, 143, 147, 47, 123, 145, 158, 167, 72): 1.202020202020202, (100, 88, 89, 76, 158, 17, 72, 47, 145): 0.6446127946127946, (23, 89, 106, 88, 40, 47, 136, 84, 73): 0.02127659574468085, (84, 40, 88, 117, 164, 197, 106, 134, 167): 0.0625, (47, 100, 143, 40, 158, 76, 88, 89, 29): 0.5166666666666667, (84, 40, 88, 136, 76, 197, 164, 117, 38): 0.07916666666666666, (73, 117, 89, 123, 92, 145, 88, 106, 167, 164): 0.34303585500394007, (38, 73, 134, 34, 76, 197, 147, 47, 143): 0.05555555555555555, (117, 76, 145, 173, 106, 158, 143, 134, 34, 135): 0.05555555555555555, (38, 34, 89, 164, 92, 23, 76, 47, 106, 173): 0.25555555555555554, (117, 164, 89, 34, 106, 47, 76, 23, 92, 173): 0.05555555555555555, (117, 47, 106, 164, 89, 34, 76, 23, 92, 173): 0.05555555555555555, (100, 89, 173, 158, 123, 135, 72, 164, 143): 0.5, (34, 88, 73, 84, 158, 106, 197, 167, 164, 92): 0.10338443888193576, (47, 147, 23, 158, 89, 117, 134, 73, 40, 106): 0.5, (34, 88, 123, 158, 73, 135, 100, 72, 164, 143): 0.10338443888193576, (17, 164, 135, 38, 158, 23, 134, 92, 145, 117): 0.1111111111111111, (38, 73, 134, 34, 76, 47, 92, 123, 54): 0.05555555555555555, (147, 23, 89, 117, 158, 47, 72, 136, 92, 76): 1.5, (73, 92, 136, 106, 47, 38, 167, 134, 123, 197): 0.2, (134, 173, 167, 117, 136, 84, 88, 38, 47, 106): 0.2, (34, 145, 73, 136, 88, 47, 76, 23, 92, 173): 0.352163900161397, (34, 88, 73, 158, 135, 92, 134, 117, 145, 76): 0.2612548092523061, (147, 38, 117, 76, 106, 40, 84, 136, 47, 73): 0.2, (34, 29, 84, 38, 117, 173, 92, 136, 17, 88): 0.0196078431372549, (145, 73, 158, 47, 88, 197, 40, 72): 0.1492227236908088, (47, 135, 38, 76, 145, 164, 134, 17, 92): 0.20202020202020202, (106, 134, 167, 88, 76, 100, 143, 40, 158, 29): 0.016666666666666666, (54, 100, 135, 89, 40, 76, 123, 143, 34, 23): 0.05555555555555555, (17, 164, 135, 136, 40, 106, 173, 23, 158, 38): 0.2, (136, 164, 123, 34, 29, 167, 89, 135, 145): 0.1111111111111111, (164, 147, 17, 145, 197, 167, 84, 106, 92): 0.2222222222222222, (73, 92, 134, 147, 23, 54, 34, 76): 0.05555555555555555, (100, 47, 136, 134, 38, 167, 106, 117, 89): 0.2, (23, 197, 164, 89, 158, 84, 72, 54, 34, 117): 0.5, (17, 143, 123, 135, 136, 147, 88, 72, 76): 1.0166666666666666, (167, 29, 17, 135, 84, 164, 34, 72, 76, 54): 0.05555555555555555, (147, 158, 40, 143, 100, 76, 88, 167, 134, 106): 0.016666666666666666, (164, 88, 106, 143, 123, 47, 158, 117, 197, 73): 0.08377659574468085, (147, 72, 54, 134, 84, 47, 135, 136, 145, 173): 1.0909090909090908, (29, 145, 158, 100, 135, 38, 72, 167, 17, 147): 1.1111111111111112, (117, 34, 17, 47, 76, 167, 88, 143, 158, 145): 0.33088730441671615, (54, 143, 164, 89, 158, 84, 72, 29, 88): 0.5625, (197, 143, 34, 123, 40, 88, 47, 158, 73): 0.040884438881935756, (145, 164, 117, 135, 106, 38, 17, 88, 54, 72): 0.29953703703703705, (72, 88, 167, 158, 173, 147, 34, 38, 89): 1.5196078431372548, (117, 34, 89, 164, 106, 47, 76, 17, 167): 0.05555555555555555, (147, 143, 88, 17, 76, 84, 158, 197, 136): 0.016666666666666666, (147, 92, 76, 117, 84, 145, 47, 134, 164, 40): 0.20202020202020202, (38, 197, 164, 117, 88, 40, 167, 89, 100, 29): 0.0625, (84, 164, 47, 54, 88, 147, 34, 117, 136, 158): 0.0821078431372549, (100, 89, 173, 84, 158, 106, 135, 164, 29): 0.5, (38, 167, 88, 23, 92, 164, 197, 173): 0.0625, (145, 143, 72, 135, 167, 34, 54, 17): 0.1111111111111111, (136, 88, 164, 76, 38, 167, 89, 47, 158): 0.5791666666666666, (106, 145, 135, 73, 92, 173, 123, 88, 167, 158): 0.28053585500394007, (38, 40, 147, 164, 72, 117, 143, 84, 73): 1.0, (145, 92, 89, 164, 17, 167, 134, 117): 0.2222222222222222, (158, 100, 173, 117, 92, 135, 38, 197, 17, 106): 0.2, (134, 100, 117, 84, 145, 72, 88, 76): 0.0537037037037037, (117, 34, 89, 164, 106, 145, 47, 17, 38, 23): 0.2909090909090909, (106, 134, 34, 88, 84, 47, 76, 92, 23, 173): 0.09183006535947712, (100, 88, 40, 147, 167, 158, 145, 123, 47, 76): 0.2557239057239057, (134, 47, 100, 147, 23, 54, 92, 34, 73, 72): 1.0, (167, 29, 158, 40, 197, 88, 47, 123, 34, 143): 0.0196078431372549, (145, 73, 17, 135, 72, 34, 164, 84, 76, 54): 0.05555555555555555, (164, 88, 106, 143, 197, 40, 34, 123): 0.0821078431372549, (145, 73, 158, 47, 123, 117, 197, 173): 0.09090909090909091, (89, 158, 84, 136, 88, 145, 34, 164, 143): 0.6191448801742919, (88, 145, 197, 47, 54, 136, 134, 76): 0.1446127946127946, (123, 34, 197, 145, 73, 136, 117, 167, 173, 134): 0.1111111111111111, (40, 38, 136, 158, 147, 88, 17, 89, 47): 0.5, (29, 76, 92, 34, 100, 106, 23, 117, 145): 0.16666666666666666, (76, 134, 164, 17, 84, 34, 147, 100, 123): 0.05555555555555555, (40, 143, 167, 145, 89, 197, 100, 136): 0.1111111111111111, (145, 106, 164, 34, 100, 84, 147, 47, 23): 0.09090909090909091, (135, 47, 134, 158, 143, 145, 106, 173): 0.09090909090909091, (38, 76, 135, 143, 92, 197, 106, 136, 34, 23): 0.25555555555555554, (106, 38, 117, 76, 147, 40, 84, 136, 47, 73): 0.2, (143, 34, 38, 92, 173, 158, 136, 117, 145, 100): 0.1111111111111111, (40, 38, 136, 147, 158, 88, 17, 72, 100): 1.0, (147, 88, 136, 92, 17, 23, 100, 40, 34, 117): 0.0196078431372549, (17, 143, 123, 135, 136, 147, 197, 72, 76, 23): 1.0, (123, 47, 147, 40, 88, 100, 145, 158, 167, 72): 1.239057239057239, (117, 34, 89, 164, 106, 76, 47, 23, 92, 173): 0.05555555555555555, (17, 167, 135, 136, 38, 100, 23, 89, 106, 40): 0.2, (47, 158, 40, 143, 88, 76, 100, 167, 134, 106): 0.016666666666666666, (89, 136, 167, 88, 54, 47, 164, 38): 0.0625, (164, 88, 106, 143, 123, 47, 117, 158, 197, 23): 0.0625, (17, 143, 123, 135, 136, 147, 76, 197, 72, 173): 1.0, (136, 88, 47, 117, 17, 72, 135, 173, 106, 147): 1.0, (158, 92, 164, 76, 38, 167, 54, 135, 72, 34): 0.05555555555555555, (147, 23, 76, 92, 38, 34, 173, 88, 89): 0.09183006535947712, (38, 145, 136, 29, 167, 143, 134, 34, 135, 76): 0.16666666666666666, (164, 147, 123, 34, 135, 89, 158, 106, 173, 145): 0.5, (76, 92, 143, 38, 117, 54, 145, 17, 40): 0.1111111111111111, (88, 89, 135, 34, 197, 100, 158, 84, 117, 136): 0.5196078431372549, (164, 173, 29, 92, 135, 143, 197, 145, 38, 40): 0.1111111111111111, (40, 89, 145, 47, 76, 88, 167, 143, 158): 0.7557239057239059, (54, 29, 17, 76, 84, 34, 147, 100, 123): 0.05555555555555555, (100, 47, 134, 135, 54, 23, 147, 72, 34): 1.0, (136, 88, 73, 34, 92, 167, 38, 76, 164): 0.17560666110415796, (164, 34, 117, 47, 123, 143, 106, 88, 73, 76): 0.17560666110415799, (100, 88, 76, 84, 173, 89, 167, 134, 106): 0.016666666666666666, (23, 135, 73, 100, 29, 173, 92, 164, 145, 47): 0.20202020202020202, (100, 89, 106, 158, 84, 173, 197, 167, 164, 92): 0.5, (38, 88, 34, 89, 92, 173, 40, 17, 54, 100): 0.0196078431372549, (40, 38, 136, 147, 158, 88, 145, 117, 17, 72): 1.037037037037037, (17, 143, 123, 135, 136, 147, 76, 38, 88, 84): 0.016666666666666666, (40, 134, 89, 147, 73, 106, 47, 72, 197, 23): 1.0, (173, 92, 38, 34, 100, 88, 72, 136, 158, 143): 0.0196078431372549, (100, 89, 173, 84, 158, 106, 197, 167): 0.5, (164, 38, 117, 89, 158, 73, 197, 23, 92): 0.5, (76, 123, 117, 145, 92, 173, 40, 17, 72, 54): 0.1111111111111111, (38, 88, 34, 89, 72, 29, 47, 136): 0.0196078431372549, (89, 117, 38, 164, 158, 34, 84, 54, 76): 0.5555555555555556, (17, 143, 123, 135, 136, 197, 72, 76, 147, 23): 1.0, (54, 100, 135, 89, 23, 143, 34, 123, 76, 40): 0.05555555555555555, (145, 143, 123, 135, 136, 147, 76, 72, 197, 23): 1.0, (17, 143, 54, 34, 164, 167, 158, 47, 89): 0.5, (84, 73, 134, 34, 76, 123, 92, 47, 89, 164): 0.05555555555555555, (38, 76, 88, 147, 158, 100, 54, 89, 73): 0.5379432624113475, (88, 72, 92, 135, 38, 197, 117, 134, 145, 76): 0.1648148148148148, (38, 134, 73, 34, 76, 123, 88, 23): 0.11310666110415797, (38, 88, 54, 72, 84, 158, 89, 143, 164): 0.5625, (136, 92, 88, 17, 158, 76, 89, 72, 145, 47): 0.7557239057239057, (143, 40, 84, 73, 29, 135, 88, 34, 72): 0.040884438881935756, (38, 167, 88, 23, 92, 173, 40, 143, 34, 123): 0.0196078431372549, (145, 73, 158, 47, 88, 135, 197, 164, 84, 29): 0.2117227236908088, (73, 197, 47, 123, 72, 34, 164, 84, 76, 54): 0.05555555555555555, (164, 135, 40, 123, 23, 88, 117, 84, 147): 0.0625, (73, 197, 47, 23, 34, 29, 89, 167, 100, 76): 0.05555555555555555, (117, 34, 89, 164, 106, 92, 23, 76, 47, 173): 0.05555555555555555, (89, 47, 158, 23, 17, 29, 106, 143, 73, 84): 0.5, (147, 23, 76, 92, 145, 197, 135, 143, 40): 0.1111111111111111, (117, 34, 164, 89, 106, 47, 145, 54, 92): 0.20202020202020202, (147, 23, 88, 89, 54, 100, 158, 73, 38): 0.5212765957446809, (164, 158, 117, 47, 123, 143, 106, 88, 197, 173): 0.0625, (34, 143, 84, 76, 17, 40, 106, 73, 72, 29): 0.05555555555555555, (73, 134, 100, 76, 158, 143, 89, 38, 72): 0.5, (100, 76, 117, 38, 106, 40, 84, 136, 47, 73): 0.2, (158, 84, 173, 89, 147, 106, 197, 167, 164, 92): 0.5, (136, 88, 76, 92, 145, 100, 143, 106, 173): 0.1648148148148148, (84, 17, 164, 76, 38, 167, 54, 135, 72, 34): 0.05555555555555555, (73, 134, 100, 76, 158, 34, 23, 143, 135, 117): 0.05555555555555555, (29, 76, 89, 23, 106, 100, 34, 92, 47, 40): 0.05555555555555555, (164, 88, 106, 143, 123, 117, 47, 72, 40): 0.0625, (89, 117, 38, 164, 158, 73, 197, 40, 72, 136): 0.5, (123, 135, 34, 47, 167, 145, 134, 84, 173, 23): 0.20202020202020202, (38, 167, 88, 23, 92, 173, 135, 84, 164, 29): 0.0625, (84, 40, 88, 117, 89, 167, 197, 164, 100, 29): 0.0625, (135, 76, 134, 23, 147, 54, 92, 34, 73): 0.05555555555555555, (117, 34, 89, 164, 76, 84, 72, 54): 0.05555555555555555, (72, 38, 47, 106, 117, 173, 89, 123, 76, 40): 0.2, (134, 72, 23, 89, 143, 197, 38, 145, 47, 167): 0.20202020202020202, (38, 76, 135, 34, 134, 143, 106, 158, 197, 23): 0.25555555555555554, (17, 143, 123, 135, 136, 72, 76, 147, 173, 145): 1.0, (73, 197, 47, 84, 88, 40, 117, 23, 123): 0.02127659574468085, (106, 145, 143, 117, 72, 164, 147, 38, 73): 1.2, (145, 73, 158, 47, 88, 197, 34, 123, 40, 143): 0.1688305668280637, (158, 73, 88, 34, 123, 135, 100, 72, 164, 143): 0.10338443888193576, (88, 173, 29, 38, 92, 135, 143, 197, 145, 40): 0.14814814814814814, (88, 29, 72, 145, 117, 123, 76, 47, 34, 136): 0.21977619330560508, (147, 72, 54, 134, 84, 136, 106, 47, 135, 40): 1.0, (17, 167, 135, 136, 100, 38, 23, 89, 145, 73): 0.1111111111111111, (197, 34, 147, 117, 135, 72, 17, 134, 38, 89): 1.0, (38, 167, 88, 23, 92, 173, 84, 164, 135, 29): 0.0625, (38, 73, 134, 40, 173, 23, 34, 164, 72, 106): 0.2, (100, 89, 173, 92, 23, 76, 106, 158, 84): 0.5, (147, 89, 134, 40, 73, 106, 47, 88, 38, 84): 0.22127659574468087, (147, 158, 92, 54, 145, 17, 40, 38, 73, 117): 0.1111111111111111, (123, 135, 34, 47, 167, 145, 72, 40, 134, 136): 0.20202020202020202, (73, 47, 84, 164, 72, 147, 123, 117, 167, 54): 1.0, (106, 89, 23, 38, 100, 136, 135, 167, 17): 0.2, (38, 164, 47, 54, 88, 147, 117, 34, 158, 40): 0.0821078431372549, (73, 197, 47, 76, 167, 23, 72, 88, 29, 100): 0.03794326241134752, (88, 72, 167, 123, 143, 47, 158, 89): 0.5, (164, 88, 38, 34, 143, 158, 100, 72, 136): 0.0821078431372549, (72, 38, 147, 173, 135, 76, 47, 100): 1.0, (164, 88, 76, 72, 135, 54, 167, 38, 34): 0.15433006535947713, (123, 92, 197, 136, 89, 88, 38, 34, 47): 0.0196078431372549, (89, 117, 38, 164, 135, 54, 100, 158, 76): 0.5, (106, 84, 88, 134, 158, 73, 197, 23, 173): 0.02127659574468085, (135, 76, 84, 117, 38, 147, 136, 34, 88, 89): 0.09183006535947712, (136, 164, 17, 147, 145, 197, 167, 84, 106, 92): 0.2222222222222222, (72, 73, 164, 84, 47, 147, 123, 117, 167, 54): 1.0, (47, 167, 135, 136, 100, 23, 38, 89, 106, 40): 0.2, (17, 158, 40, 143, 167, 88, 76, 100, 134, 106): 0.016666666666666666, (40, 88, 158, 147, 136, 38, 17, 117, 76): 0.016666666666666666, (106, 84, 88, 134, 135, 145, 158, 100, 54): 0.037037037037037035, (147, 158, 73, 23, 145, 17, 40, 38, 92, 173): 0.1111111111111111, (117, 34, 89, 164, 106, 47, 92, 54, 76): 0.05555555555555555, (106, 134, 136, 100, 17, 47, 145, 84, 88, 34): 0.14755397108338286, (76, 134, 164, 145, 167, 143, 40, 38, 197, 23): 0.1111111111111111, (17, 38, 136, 147, 158, 88, 117, 145, 100): 0.037037037037037035, (40, 143, 123, 72, 76, 147, 136, 135, 197, 23): 1.0, (84, 76, 89, 147, 88, 54, 100, 158, 73, 136): 0.5379432624113476, (164, 38, 47, 54, 88, 147, 34, 117, 158): 0.0821078431372549, (73, 117, 167, 106, 88, 145, 123, 34, 143, 23): 0.1890325870300839, (34, 72, 73, 106, 40, 17, 76, 84, 29, 143): 0.05555555555555555, (40, 89, 145, 47, 88, 106, 123, 17, 34, 134): 0.14755397108338286, (173, 197, 76, 17, 34, 84, 147, 100, 123): 0.05555555555555555, (34, 145, 88, 73, 136, 100, 173, 106, 40): 0.07792147591897279, (197, 92, 123, 136, 47, 34, 38, 76, 23, 173): 0.05555555555555555, (100, 89, 173, 84, 158, 106, 197, 167, 29): 0.5, (38, 92, 23, 88, 167, 173, 135, 164): 0.0625, (73, 72, 145, 164, 34, 100, 84, 147, 47, 23): 1.0909090909090908, (100, 89, 135, 40, 34, 123, 76, 143, 23): 0.05555555555555555, (136, 88, 164, 76, 100, 38, 23, 89, 106, 40): 0.2791666666666667, (135, 54, 134, 76, 167, 23, 100, 29, 88, 72): 0.016666666666666666, (76, 123, 117, 145, 72, 34, 47, 88, 29, 136): 0.21977619330560505, (84, 143, 40, 158, 47, 136, 135, 145, 73): 0.09090909090909091, (147, 72, 54, 134, 100, 88, 76, 167, 106): 1.0166666666666666, (34, 143, 17, 145, 88, 100, 158, 89, 134, 106): 0.5566448801742919, (47, 158, 40, 143, 100, 76, 88, 167, 123): 0.016666666666666666, (136, 135, 23, 147, 158, 47, 143, 123, 167, 72): 1.0, (88, 164, 17, 147, 145, 106, 84, 167, 197, 92): 0.32175925925925924, (167, 34, 134, 143, 158, 136, 72, 88, 100): 0.0196078431372549, (88, 72, 167, 123, 143, 23, 147, 158, 47, 135): 1.0, (164, 88, 106, 143, 123, 158, 117, 47, 92, 173): 0.0625, (117, 34, 89, 164, 106, 23, 76, 47, 197, 173): 0.05555555555555555, (23, 92, 73, 135, 38, 89, 88, 167, 197, 123): 0.02127659574468085, (34, 54, 72, 143, 147, 173, 167, 134, 158, 135): 1.0, (164, 158, 117, 47, 123, 143, 106, 88, 197): 0.0625, (38, 73, 134, 34, 76, 47, 92, 123, 89, 173): 0.05555555555555555, (147, 72, 54, 134, 84, 47, 92, 23, 76, 173): 1.0, (117, 34, 89, 164, 106, 136, 145, 47, 135, 73): 0.09090909090909091, (167, 34, 54, 134, 136, 84, 135, 47, 145, 73): 0.20202020202020202, (147, 72, 134, 88, 117, 173, 100, 47, 40): 1.0, (73, 197, 123, 47, 23, 117, 40, 88, 84, 147): 0.02127659574468085, (72, 167, 158, 145, 123, 47, 147, 40, 88, 100): 1.239057239057239, (197, 106, 100, 34, 92, 76, 29, 167, 164): 0.05555555555555555, (100, 89, 173, 84, 23, 106, 158, 47, 40): 0.5, (40, 167, 34, 76, 84, 17, 145, 89, 136): 0.16666666666666666, (145, 173, 29, 54, 47, 38, 164, 147, 100, 123): 0.09090909090909091, (88, 173, 29, 145, 38, 197, 143, 135, 92, 40): 0.14814814814814814, (117, 34, 89, 164, 106, 23, 76, 47, 92, 173): 0.05555555555555555, (136, 88, 123, 100, 158, 38, 167, 89): 0.5, (164, 47, 76, 38, 167, 34, 72, 135, 54): 0.05555555555555555, (89, 117, 197, 73, 158, 164, 38, 23): 0.5, (84, 76, 88, 147, 89, 54, 100, 158, 173): 0.5166666666666667, (147, 23, 76, 92, 136, 72, 145, 54, 117): 1.1111111111111112, (106, 84, 88, 134, 135, 54, 100, 38, 158, 76): 0.21666666666666667, (23, 89, 106, 88, 72, 34, 164, 84, 76, 54): 0.15433006535947713, (136, 88, 164, 76, 38, 167, 54, 23, 173): 0.07916666666666666, (135, 47, 134, 145, 136, 106, 197, 92, 34, 143): 0.20202020202020202, (136, 88, 164, 135, 54, 167, 38, 76, 72, 23): 0.07916666666666666, (29, 84, 88, 38, 158, 23, 173, 106, 40, 136): 0.2, (17, 167, 135, 136, 100, 38, 23, 89, 106): 0.2, (17, 143, 123, 135, 136, 72, 76, 147, 197, 40): 1.0, (47, 147, 134, 117, 89, 158, 23, 123, 40, 73): 0.5, (40, 76, 84, 17, 145, 89, 34, 147, 100, 106): 0.05555555555555555, (117, 158, 84, 72, 54, 34, 89, 164, 143, 88): 0.5821078431372549, (147, 76, 117, 136, 145, 73, 197, 34, 123): 0.05555555555555555, (134, 173, 167, 38, 106, 73, 47, 136, 84, 40): 0.2, (47, 143, 197, 134, 145, 117, 84, 76, 92): 0.20202020202020202, (147, 158, 134, 167, 88, 76, 100, 143, 40, 106): 0.016666666666666666, (134, 173, 167, 117, 136, 73, 145, 34, 17): 0.1111111111111111, (135, 76, 84, 147, 38, 117, 136, 197, 34, 123): 0.05555555555555555, (164, 135, 40, 23, 34, 167, 134, 92, 145, 117): 0.2222222222222222, (145, 73, 23, 17, 197, 88, 47, 158): 0.1492227236908088, (40, 143, 88, 89, 145, 72, 17, 158, 76, 47): 0.6446127946127946, (164, 88, 106, 143, 123, 47, 117, 197, 158, 173): 0.0625, (117, 34, 89, 164, 106, 47, 76, 23, 17, 92): 0.05555555555555555, (173, 92, 164, 134, 145, 47, 76, 38, 135, 29): 0.20202020202020202, (40, 164, 34, 76, 84, 17, 145, 89, 92): 0.16666666666666666, (29, 135, 38, 76, 47, 145, 134, 147, 100, 123): 0.09090909090909091, (197, 40, 29, 73, 106, 47, 38, 84, 88): 0.22127659574468087, (147, 89, 134, 158, 88, 38, 34, 173): 0.5196078431372549, (117, 34, 89, 164, 106, 17, 145, 92, 54): 0.1111111111111111, (73, 134, 100, 158, 76, 143, 23, 34, 135, 117): 0.05555555555555555, (88, 145, 47, 23, 134, 136, 54, 197, 158, 73): 0.1492227236908088, (145, 73, 158, 84, 40, 117, 88, 47, 147): 0.1492227236908088, (117, 134, 106, 34, 89, 38, 92, 88): 0.2196078431372549, (147, 89, 134, 40, 76, 123, 34, 143, 23): 0.05555555555555555, (54, 100, 135, 89, 73, 106, 84, 88, 38, 47): 0.22127659574468087, (89, 84, 73, 143, 29, 106, 38, 76, 23, 173): 0.2, (38, 167, 76, 173, 92, 23, 88, 84, 143, 29): 0.016666666666666666, (47, 38, 197, 158, 143, 76, 88, 123, 134, 23): 0.016666666666666666, (173, 136, 17, 88, 117, 38, 164, 106, 92): 0.2625, (34, 29, 84, 100, 145, 147, 47, 23): 0.09090909090909091, (73, 197, 47, 123, 23, 117, 40, 88, 84): 0.02127659574468085, (147, 134, 54, 72, 84, 136, 135, 47, 145): 1.0909090909090908, (173, 92, 38, 34, 143, 158, 136, 72, 106, 134): 0.2, (47, 158, 40, 143, 100, 76, 88, 167): 0.016666666666666666, (100, 89, 173, 84, 158, 106, 136, 34, 47, 88): 0.5196078431372549, (76, 123, 117, 145, 72, 29, 197, 167, 164, 92): 0.2222222222222222, (47, 147, 134, 117, 100, 34, 158, 89, 123): 0.5, (147, 158, 73, 38, 40, 17, 145, 92, 54, 117): 0.1111111111111111, (134, 72, 23, 167, 89, 143, 197, 38, 145, 47): 0.20202020202020202, (147, 72, 54, 134, 106, 47, 76, 23, 92, 173): 1.0, (117, 34, 89, 164, 84, 136, 135, 47, 145, 73): 0.09090909090909091, (158, 34, 54, 72, 84, 89, 164, 143, 88): 0.5821078431372549, (117, 92, 47, 17, 147, 106, 173, 72, 135): 1.0, (123, 40, 197, 88, 47, 158, 73, 145, 34, 143): 0.1688305668280637, (17, 164, 158, 38, 135, 23, 173, 106, 40, 136): 0.2, (84, 34, 100, 173, 88, 47, 54, 17, 106): 0.0196078431372549, (84, 92, 76, 17, 145, 100, 136, 143, 23): 0.1111111111111111, (34, 72, 73, 106, 147, 40, 76, 197, 23): 1.0555555555555556, (17, 167, 100, 136, 135, 38, 23, 89, 106): 0.2, (47, 147, 134, 117, 89, 158, 73, 23, 40): 0.5, (89, 100, 173, 84, 158, 106, 123, 117, 167, 54): 0.5, (73, 72, 164, 84, 47, 147, 197, 167, 92): 1.0, (38, 73, 197, 158, 143, 84, 117, 136, 106, 40): 0.2, (47, 38, 134, 92, 76, 34, 123, 89, 164): 0.05555555555555555, (135, 76, 84, 117, 17, 147, 106, 173, 72): 1.0, (38, 167, 123, 34, 135, 89, 29, 136, 145): 0.1111111111111111, (164, 147, 88, 23, 92, 173, 135, 84, 29): 0.0625, (23, 135, 73, 100, 29, 164, 92, 173, 145, 106): 0.1111111111111111, (134, 147, 47, 117, 89, 158, 23, 73, 40): 0.5, (34, 197, 147, 117, 40, 76, 123, 143, 23): 0.05555555555555555, (100, 89, 173, 134, 167, 38, 47, 106, 117): 0.2, (34, 145, 88, 106, 167, 117, 73, 147, 100, 123): 0.18903258703008388, (106, 84, 88, 134, 135, 54, 100, 38, 158, 72): 0.2, (29, 145, 158, 100, 73, 84, 76, 89, 38): 0.5, (88, 145, 134, 147, 23, 54, 92, 34, 73, 76): 0.26125480925230615, (135, 54, 88, 147, 89, 100, 158, 73, 38): 0.5212765957446809, (84, 76, 134, 100, 29, 88, 72, 23, 167): 0.016666666666666666, (89, 167, 34, 23, 40, 135, 164, 29, 100, 76): 0.05555555555555555, (145, 38, 47, 54, 29, 173, 164, 136, 167, 89): 0.20202020202020202, (123, 92, 197, 136, 143, 76, 38, 34, 47, 23): 0.05555555555555555, (135, 145, 134, 47, 136, 106, 197, 92, 23, 173): 0.20202020202020202, (23, 92, 72, 143, 147, 173, 158, 145, 106): 1.1111111111111112, (143, 134, 34, 135, 76, 38, 167, 158): 0.05555555555555555, (145, 173, 106, 158, 143, 134, 34, 135, 76, 38): 0.25555555555555554, (38, 76, 135, 34, 145, 173, 106, 158, 143, 134): 0.25555555555555554, (73, 72, 164, 88, 34, 76, 117, 54, 29, 158): 0.17560666110415796, (84, 72, 38, 47, 147, 123, 117, 167, 54): 1.0, (88, 72, 167, 123, 143, 47, 40, 147, 84): 1.0, (197, 164, 117, 135, 38, 106, 17, 72, 47, 73): 0.2, (147, 76, 117, 106, 38, 40, 84, 136, 54, 88): 0.21666666666666667, (29, 54, 47, 38, 145, 173, 164, 167, 136, 89): 0.20202020202020202, (134, 173, 167, 117, 136, 73, 100, 197, 145): 0.1111111111111111, (76, 134, 164, 143, 167, 145, 40, 197, 34, 123): 0.16666666666666666, (38, 76, 135, 34, 100, 106, 158, 143, 134, 136): 0.25555555555555554, (76, 134, 164, 145, 167, 143, 40, 197, 173): 0.1111111111111111, (147, 158, 73, 38, 88, 100, 89, 167, 123): 0.5212765957446809, (34, 143, 17, 145, 40, 54, 92, 117): 0.1111111111111111, (100, 88, 89, 23, 92, 173, 135, 164, 84, 29): 0.0625, (38, 167, 84, 173, 158, 106, 197, 164, 92): 0.2, (73, 197, 47, 123, 117, 23, 40, 88, 84, 147): 0.02127659574468085, (100, 197, 76, 88, 123, 84, 173, 47, 134, 23): 0.016666666666666666, (34, 38, 84, 29, 117, 88, 17, 136, 92, 173): 0.0196078431372549, (47, 158, 40, 143, 100, 76, 88, 134, 167, 106): 0.016666666666666666, (106, 134, 34, 17, 47, 145, 84, 88): 0.14755397108338286, (89, 134, 117, 34, 106, 38, 92, 143, 23): 0.2, (145, 38, 47, 54, 29, 158, 136, 72, 88, 100): 0.12794612794612795, (100, 47, 134, 147, 23, 54, 76, 73, 34, 92): 0.05555555555555555, (117, 34, 89, 164, 106, 47, 76, 92, 23, 173): 0.05555555555555555, (106, 84, 88, 134, 135, 54, 92, 145, 117): 0.14814814814814814, (38, 73, 134, 34, 76, 47, 92, 89, 123, 164): 0.05555555555555555, (145, 92, 89, 164, 147, 173, 167, 134, 158, 135): 0.7222222222222222, (89, 136, 158, 167, 164, 34, 54, 17, 143, 145): 0.6111111111111112, (145, 38, 47, 54, 29, 173, 164, 89, 167): 0.20202020202020202, (29, 76, 40, 147, 47, 123, 145, 158, 167, 72): 1.202020202020202, (100, 88, 92, 34, 106, 23, 89, 47, 40): 0.0196078431372549, (197, 164, 117, 135, 106, 38, 17, 72, 54): 0.2, (147, 23, 76, 92, 136, 72, 47, 158, 123, 88): 1.0166666666666666, (117, 34, 89, 164, 158, 143, 23, 135): 0.5, (89, 135, 100, 54, 40, 76, 123, 34, 143, 23): 0.05555555555555555, (73, 117, 167, 106, 88, 145, 147, 197, 38, 143): 0.36942474389282903, (34, 145, 88, 134, 135, 54, 158, 100, 38, 76): 0.12886710239651417, (134, 54, 117, 164, 100, 73, 136, 88, 84, 106): 0.08377659574468085, (147, 89, 134, 40, 73, 106, 47, 38, 84, 88): 0.22127659574468087, (38, 73, 134, 34, 76, 47, 92, 123, 164, 89): 0.05555555555555555, (164, 147, 123, 34, 135, 89, 145, 136, 29, 167): 0.1111111111111111, (167, 34, 134, 100, 173, 40, 47, 88, 117, 72): 0.0196078431372549, (40, 143, 88, 89, 17, 158, 76, 73, 38): 0.5379432624113475, (84, 88, 76, 147, 89, 54, 100, 72, 145, 47): 1.1446127946127946, (23, 47, 72, 92, 88, 106, 123, 17, 34, 134): 0.0196078431372549, (123, 100, 147, 34, 76, 84, 17, 29, 167): 0.05555555555555555, (40, 89, 145, 164, 34, 72, 135, 84, 76, 54): 0.05555555555555555, (145, 106, 73, 54, 47, 38, 88, 84): 0.3492227236908088, (158, 117, 47, 92, 17, 147, 106, 173, 135, 72): 1.0, (23, 135, 73, 100, 29, 164, 173, 92, 145, 47): 0.20202020202020202, (73, 117, 167, 88, 106, 34, 164, 84, 76, 54): 0.17560666110415796, (167, 135, 17, 29, 72, 145, 147, 38, 197, 143): 1.1111111111111112, (167, 76, 89, 47, 164, 23, 72, 88, 29, 100): 0.07916666666666666, (135, 54, 106, 84, 117, 72, 147, 123, 134): 1.0, (147, 89, 134, 72, 47, 106, 73, 40, 164, 143): 1.0, (34, 88, 73, 158, 123, 135, 100, 38, 84): 0.040884438881935756, (38, 76, 88, 54, 72, 17, 106, 34, 135): 0.29183006535947714, (84, 17, 136, 100, 145, 92, 76, 143, 106, 47): 0.20202020202020202, (89, 84, 73, 143, 106, 29, 17, 23, 158, 173): 0.5, (117, 89, 38, 164, 158, 47, 197, 173): 0.5, (164, 88, 106, 143, 123, 73, 173, 23, 197, 84): 0.08377659574468085, (106, 47, 38, 72, 117, 173, 123, 89, 100, 136): 0.2, (76, 134, 164, 145, 167, 143, 40, 197): 0.1111111111111111, (147, 23, 76, 123, 158, 47, 72, 136, 92, 197): 1.0, (23, 135, 73, 100, 117, 92, 54, 145, 17, 40): 0.1111111111111111, (147, 73, 158, 38, 29, 164, 92, 173, 145, 47): 0.20202020202020202, (147, 89, 134, 40, 73, 106, 47, 38, 88, 173): 0.22127659574468087, (123, 92, 38, 34, 47, 136, 197, 76, 23, 84): 0.05555555555555555, (29, 135, 38, 76, 47, 145, 134, 17, 164, 92): 0.20202020202020202, (38, 88, 34, 89, 40, 117, 92, 54, 145, 17): 0.16775599128540303, (147, 158, 73, 38, 92, 173, 40, 17, 54, 72): 1.0, (135, 47, 134, 145, 136, 40, 88, 117, 72): 0.12794612794612795, (197, 106, 158, 17, 145, 89, 40, 167, 164, 92): 0.7222222222222223, (100, 89, 173, 84, 76, 147, 34, 123): 0.05555555555555555, (106, 134, 34, 92, 197, 167, 47, 145, 84, 88): 0.369776193305605, (136, 164, 17, 147, 84, 106, 145, 38, 23): 0.2, (40, 89, 145, 164, 106, 47, 76, 23, 92, 173): 0.20202020202020202, (117, 34, 89, 17, 123, 100, 147, 76, 84): 0.05555555555555555, (134, 72, 164, 147, 173, 117, 143, 38, 73, 84): 1.0, (106, 145, 167, 117, 136, 73, 197, 34, 123): 0.1111111111111111, (117, 34, 89, 164, 106, 47, 72, 147, 17, 167): 1.0, (84, 40, 106, 38, 117, 23, 147, 136, 47, 73): 0.2, (147, 76, 158, 47, 72, 136, 92, 123, 197): 1.0, (117, 34, 76, 143, 84, 164, 89, 17, 88, 136): 0.15433006535947713, (34, 54, 88, 167, 197, 123, 89, 38, 135, 73): 0.040884438881935756, (23, 89, 106, 34, 92, 100, 88, 73, 76): 0.11310666110415797, (34, 72, 73, 106, 40, 17, 92, 47, 145, 173): 0.20202020202020202, (23, 89, 106, 88, 100, 92, 76, 73, 47, 136): 0.03794326241134752, (147, 76, 117, 38, 106, 40, 164, 136, 84): 0.2, (17, 145, 47, 197, 54, 136, 134, 23, 158, 73): 0.09090909090909091, (88, 164, 135, 38, 158, 23, 173, 106, 40, 136): 0.2625, (145, 40, 197, 88, 47, 158, 73, 123, 34, 143): 0.1688305668280637, (147, 158, 73, 92, 54, 145, 17, 40, 38, 117): 0.1111111111111111, (158, 92, 47, 117, 17, 147, 173, 106, 135, 72): 1.0, (117, 34, 89, 164, 106, 47, 158, 76, 38): 0.7555555555555555, (17, 143, 123, 135, 136, 147, 76, 72, 197): 1.0, (40, 23, 100, 147, 34, 76, 84, 17, 145, 89): 0.05555555555555555, (117, 34, 89, 164'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semratings_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['08',\n",
       " '7',\n",
       " '',\n",
       " '85',\n",
       " '555555555555',\n",
       " '',\n",
       " ' 76',\n",
       " '49',\n",
       " '97',\n",
       " ' 23): 0.1111111111111111',\n",
       " ' (158',\n",
       " '55555555',\n",
       " '.15433006535947713',\n",
       " '0.09090909090909091',\n",
       " '.056644880174292',\n",
       " '1.202020202020202',\n",
       " '916666666666666',\n",
       " '136): 0.2909090909090909',\n",
       " '965142',\n",
       " '4814814814814814',\n",
       " '4',\n",
       " ' 73',\n",
       " '64',\n",
       " '',\n",
       " '58',\n",
       " '555555555555',\n",
       " '037',\n",
       " '.31313131313131315',\n",
       " ' (89',\n",
       " ' 158',\n",
       " '13131',\n",
       " '4',\n",
       " ': 0.1111111111111111',\n",
       " ' 143',\n",
       " '935756',\n",
       " ' 17): 0.31313131313131315',\n",
       " ': 0.2',\n",
       " '4',\n",
       " '',\n",
       " '47',\n",
       " '111',\n",
       " ' 38',\n",
       " '0',\n",
       " '0.1162037037037037',\n",
       " '.0625',\n",
       " '(23',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " ' 38',\n",
       " '',\n",
       " ': 0.1111111111111111',\n",
       " '',\n",
       " '2',\n",
       " '111111111',\n",
       " ' 106): 0.22127659574468087',\n",
       " '72549',\n",
       " ' 54',\n",
       " '73',\n",
       " '02020202',\n",
       " ' 88',\n",
       " '11111111111112',\n",
       " '3300653594772',\n",
       " ': 0.2',\n",
       " '',\n",
       " '147',\n",
       " '5',\n",
       " '',\n",
       " '(117',\n",
       " '38',\n",
       " '0.2222222222222222',\n",
       " '55556',\n",
       " '1078431372549',\n",
       " '',\n",
       " '7575757',\n",
       " '1111112',\n",
       " '75757',\n",
       " '54',\n",
       " '02020202020202',\n",
       " '55555555555',\n",
       " ' 147',\n",
       " '7',\n",
       " '1446127946127946',\n",
       " '9',\n",
       " '85',\n",
       " ' (117',\n",
       " '36',\n",
       " '158): 0.02127659574468085',\n",
       " '4',\n",
       " '59259259259',\n",
       " '0.09183006535947712',\n",
       " ' 164',\n",
       " '',\n",
       " '): 0.0196078431372549',\n",
       " '23): 0.05555555555555555',\n",
       " '37037037037',\n",
       " '',\n",
       " '23',\n",
       " '485914105594955',\n",
       " ' 54',\n",
       " '27659574468085',\n",
       " '0',\n",
       " '8431372549',\n",
       " '2',\n",
       " '7',\n",
       " '.09090909090909091',\n",
       " ' 0.05555555555555555',\n",
       " '7',\n",
       " '(143',\n",
       " ' 29',\n",
       " '145',\n",
       " '4',\n",
       " '84',\n",
       " ' 164): 0.16666666666666666',\n",
       " '9090909090909091',\n",
       " '7',\n",
       " ' 92',\n",
       " '088',\n",
       " '20202020202020202',\n",
       " '757576',\n",
       " '7',\n",
       " ' 89',\n",
       " '',\n",
       " '3',\n",
       " '0.08377659574468085',\n",
       " '(100',\n",
       " '.5',\n",
       " '9',\n",
       " '555555555556',\n",
       " '',\n",
       " '92',\n",
       " '2',\n",
       " '0625',\n",
       " '100']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_solution_fitness_list = []\n",
    "\n",
    "for best_solution, semratings_dict in zip(best_solution_list,semratings_dict_list):\n",
    "    best_solution = str(tuple(best_solution))\n",
    "    start = semratings_dict.find(best_solution)\n",
    "    end = start + len(best_solution) + len(\": \")\n",
    "    end2 = semratings_dict.find(\",\",end)\n",
    "    best_solution_fitness = semratings_dict[end:end2]\n",
    "    best_solution_fitness_list.append(best_solution_fitness)\n",
    "\n",
    "best_solution_fitness_list\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "separator = \": \"\n",
    "\n",
    "end_index = search_string.find(',',start_index)\n",
    "end_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.02127659574468085'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_solution = [89, 73, 106, 88, 84]\n",
    "fitness_scores_dict = '{(89, 73, 106, 88, 84): 0.02127659574468085, }'\n",
    "\n",
    "best_solution = str(tuple(best_solution))\n",
    "\n",
    "start = fitness_scores_dict.find(best_solution)\n",
    "end = start + len(best_solution) + len(\": \")\n",
    "end2 = fitness_scores_dict.find(\",\",end)\n",
    "\n",
    "best_solution_fitness = fitness_scores_dict[end:end2]\n",
    "best_solution_fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = 0\n",
    "end = search_string.find(\":\")\n",
    "search_string.find(str(tuple(my_list)), start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end = search_string.find(\":\")\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
